<!DOCTYPE html PUBLIC "-//WAPFORUM//DTD XHTML Mobile 1.0//EN" "http://www.wapforum.org/DTD/xhtml-mobile10.dtd">
<html>
  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport"content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=yes"/>
  
  
  <title>  Min‘s blog</title>

 
  
    <link rel="icon" href="/img/favicon.png">
  


  <!-- css -->
  <link rel="stylesheet" href="/css/style.css">  
  <!-- Jquery -->
  <script src="//cdn.staticfile.org/jquery/3.2.1/jquery.min.js"></script> 
  <!-- Add fancyBox -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.25/jquery.fancybox.min.js"></script> 
  <script src="/js/gallery.js"></script>
  <!-- javascript --> 
  <script src="/js/mobile.js"></script>  
  <script src="/js/utils.js"></script>    
  <script src="/js/script.js"></script>  
</head> 
  <body> 
    <header class="header">
	
  <nav class="header-nav">       
	
  	<span class="iconfont icon-menu mobile-toggle"></span>  

    <a class="header-logo" href="/"><span>Min&#39;s blog</a>  

    <div class="header-menu">          
              
            

              <a class="header-menu-link" id="header-menu-home" href="/">首页</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-archives" href="/archives">归档</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-categories" href="/categories">分类</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-tags" href="/tags">标签</a>     

            
            
            

              <a class="header-menu-link" id="header-menu-about" href="/about">关于</a>     

            
            
            

              <a class="iconfont icon-menu-search header-menu-link" id="header-menu-search"></a>

            
                
    </div>  
    
  </nav>
</header>

    <div class="container">         
      
        

          <section id="main">  

        

        


<div class="profile sildeUpMin">

		<img class="avatar no-gallery" src="/img/timg.jpeg"  alt="Lose">
					
		<p class="author">Rui Min</p>

		
			<p class="location"><span class="iconfont icon-location"></span>BeiJing CN</p>
		
	
		<div class="social">
   		    	
		<a href="https://github.com/bjcoder" class="iconfont icon-github" target="_blank" title="github"></a>
	        	
		<a href="/" class="iconfont icon-others" target="_blank" title="others"></a>
	    
    	</div>		
</div>

      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/05/06/spark on yarn/">spark on yarn</a>  
	       
		 

		 <time>2018-05-06 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<p><strong>摘要</strong></p>
<p>在Spark中，有Yarn-Client和Yarn-Cluster两种模式可以运行在Yarn上，通常Yarn-Cluster适用于生产环境，而Yarn-Clientr更适用于交互，调试模式，以下是它们的区别</p>
<p><strong>Spark插拨式资源管理</strong></p>
<p>Spark支持Yarn,Mesos,Standalone三种集群部署模式，它们的共同点：Master服务(Yarn ResourceManager,Mesos master,Spark standalone)来决定哪些应用可以运行以及在哪什么时候运行，Slave服务(Yarn NodeManger)运行在每个节点上，节点上实际运行着Executor进程，此外还监控着它们的运行状态以及资源的消耗</p>
<p><strong>Spark On Yarn的优势</strong></p>
<p>\1. Spark支持资源动态共享，运行于Yarn的框架都共享一个集中配置好的资源池</p>
<p>\2. 可以很方便的利用Yarn的资源调度特性来做分类·，隔离以及优先级控制负载，拥有更灵活的调度策略</p>
<p>3.Yarn可以自由地选择executor数量</p>
<p>4.Yarn是唯一支持Spark安全的集群管理器，使用Yarn，Spark可以运行于Kerberized Hadoop之上，在它们进程之间进行安全认证 </p>
<p><strong>Yarn-cluster VS Yarn-client</strong></p>
<p>当在Spark On Yarn模式下，每个Spark Executor作为一个Yarn container在运行，同时支持多个任务在同一个container中运行，极大地节省了任务的启动时间</p>
<p><strong>Appliaction Master</strong></p>
<p>为了更好的理解这两种模式的区别先了解下Yarn的Application Master概念，在Yarn中，每个application都有一个Application Master进程，它是Appliaction启动的第一个容器，它负责从ResourceManager中申请资源，分配资源，同时通知NodeManager来为Application启动container，Application Master避免了需要一个活动的client来维持，启动Applicatin的client可以随时退出，而由Yarn管理的进程继续在集群中运行</p>
<p><strong>Yarn-cluster</strong></p>
<p>在Yarn-cluster模式下，driver运行在Appliaction Master上，Appliaction Master进程同时负责驱动Application和从Yarn中申请资源，该进程运行在Yarn container内，所以启动Application Master的client可以立即关闭而不必持续到Application的生命周期，下图是yarn-cluster模式</p>
<p><img src="https://images2015.cnblogs.com/blog/776259/201609/776259-20160909165742332-1159110454.png" alt="img"></p>
<p><strong>Yarn-cluster模式下作业执行流程：</strong></p>
<p>\1. 客户端生成作业信息提交给ResourceManager(RM)</p>
<p>\2. RM在某一个NodeManager(由Yarn决定)启动container并将Application Master(AM)分配给该NodeManager(NM)</p>
<p>\3. NM接收到RM的分配，启动Application Master并初始化作业，此时这个NM就称为Driver</p>
<p>\4. Application向RM申请资源，分配资源同时通知其他NodeManager启动相应的Executor</p>
<p><strong>Yarn-client</strong></p>
<p>在Yarn-client中，Application Master仅仅从Yarn中申请资源给Executor，之后client会跟container通信进行作业的调度，下图是Yarn-client模式</p>
<p><img src="https://images2015.cnblogs.com/blog/776259/201609/776259-20160909165804926-17816733.png" alt="img"></p>
<p><strong>Yarn-client模式下作业执行流程：</strong></p>
<p>\1. 客户端生成作业信息提交给ResourceManager(RM)</p>
<p>\2. RM在本地NodeManager启动container并将Application Master(AM)分配给该NodeManager(NM)</p>
<p>\3. NM接收到RM的分配，启动Application Master并初始化作业，此时这个NM就称为Driver</p>
<p>\4. Application向RM申请资源，分配资源同时通知其他NodeManager启动相应的Executor</p>
<p>\5. Executor向本地启动的Application Master注册汇报并完成相应的任务</p>
<p> <img src="file:///D:/%E4%B8%BA%E7%9F%A5%E7%AC%94%E8%AE%B0%E6%95%B0%E6%8D%AE/temp/87e4b7ac-f143-47b6-9b6e-20b5ea662ce9/128/index_files/de48a141-d70f-4b25-b1ea-08f2a17a4ea6.png" alt="img"><img src="https://images2015.cnblogs.com/blog/776259/201609/776259-20160909165822723-1513641104.png" alt="img"></p>
<p>参考资料：<a href="http://blog.cloudera.com/blog/2014/05/apache-spark-resource-management-and-yarn-app-models/" target="_blank" rel="noopener">Apache Spark Resource Management and YARN App Models</a></p>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/大数据/">大数据</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/spark/">spark</a> <a class="tag-link" href="/tags/复习/">复习</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		1832
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/05/06/spark on yarn/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/05/06/Hive sql/">Hive sql</a>  
	       
		 

		 <time>2018-05-06 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<h1 id="分组top-N"><a href="#分组top-N" class="headerlink" title="分组top N"></a>分组top N</h1><p>Hive在0.11.0版本开始加入了row_number、rank、dense_rank分析函数，可以查询分组排序后的top值</p>
<p><strong>说明：</strong></p>
<p>row_number() over ([partition col1] [order by col2])</p>
<p>rank() over ([partition col1] [order by col2])</p>
<p>dense_rank() over ([partition col1] [order by col2])</p>
<p>它们都是根据col1字段分组，然后对col2字段进行排序，对排序后的每行生成一个行号，这个行号从1开始递增</p>
<p>col1、col2都可以是多个字段，用’,’分隔</p>
<p>区别：</p>
<p>1）row_number：不管col2字段的值是否相等，行号一直递增，比如：有两条记录的值相等，但一个是第一，一个是第二</p>
<p>3）dense_rank：上下两条记录的col2相等时，下一个col2值的行号递增1，比如：有两条并列第一，下一个是第二</p>
<p>row_number可以实现分页查询</p>
<p>实例：</p>
<ol>
<li><code>hive&gt; create table t(name string, sub string, score int) row format delimited fields terminated by &#39;\t&#39;;</code></li>
</ol>
<p>数据在附件的a.txt里</p>
<ol>
<li><code>a    chinese    98</code></li>
<li><code>a    english    90</code></li>
<li><code>d    chinese    88</code></li>
<li><code>c    english    82</code></li>
<li><code>c    math    98</code></li>
<li><code>b    math    89</code></li>
<li><code>b    chinese    79</code></li>
<li><code>z    english    90</code></li>
<li><code>z    math    89</code></li>
<li><code>z    chinese    80</code></li>
<li><code>e    math    99</code></li>
<li><code>e    english    87</code></li>
<li><code>d    english    90</code></li>
</ol>
<p><strong>1、row_number</strong></p>
<ol>
<li><code>hive (test)&gt; select *, row_number() over (partition by sub order by score) as od from t;</code></li>
</ol>
<p><strong>2、rank</strong></p>
<ol>
<li><code>hive (test)&gt; select *, rank() over (partition by sub order by score) as od from t;</code></li>
</ol>
<p><strong>3、dense_ran</strong></p>
<ol>
<li><code>hive (test)&gt; select *, dense_rank() over (partition by sub order by score desc) from t;</code></li>
</ol>
<p>业务实例：</p>
<p>统计每个学科的前三名</p>
<ol>
<li><code>select * from (select *, row_number() over (partition by sub order by score desc) as od from t ) t where od&lt;=3;</code></li>
</ol>
<p>语文成绩是80分的排名是多少</p>
<ol>
<li><code>hive (test)&gt; select od from (select *, row_number() over (partition by sub order by score desc) as od from t )t where sub=&#39;chinese&#39; and score=80;</code></li>
</ol>
<p>分页查询</p>
<ol>
<li><code>hive (test)&gt; select * from (select *, row_number() over () as rn from t) t1 where rn between 1 and 5;</code></li>
</ol>
<h1 id="UV"><a href="#UV" class="headerlink" title="UV"></a>UV</h1><p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/20180312174642168.png" alt="img"></p>
<p>select store,count(distinct uid) as uv from Visit group by store;</p>
<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/20180312174739253.png" alt="img"></p>
<p>select * from Users order by age desc, total;</p>
<h1 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h1><p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/20180312174821660.png" alt="img"></p>
<p>select  stage_someone, count(distinct UID)  from  LifeStage  lateral  view  explode(split(stage,’,’))  LifeStage_tmp  as stage_someone  group  by  stage_someone;</p>
<h1 id="列转行"><a href="#列转行" class="headerlink" title="列转行"></a>列转行</h1><p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/2018031217492340.png" alt="img"></p>
<p>select UID,concat_ws(‘,’,collect_set(stage)) as stages from LifeStage group by UID;</p>
<h1 id="sql除法"><a href="#sql除法" class="headerlink" title="sql除法"></a>sql除法</h1><p>a    chinese    98</p>
<p>a    english    90</p>
<p>d    chinese    88</p>
<p>c    english    82</p>
<p>c    math    98</p>
<p>b    math    89</p>
<p>b    chinese    79</p>
<p>z    english    90</p>
<p>z    math    89</p>
<p>z    chinese    80</p>
<p>e    math    99</p>
<p>e    english    87</p>
<p>d    english    90</p>
<p>求a的chinese成绩/english成绩</p>
<p>select name,t1.score/t2.score from (select <em> from t where sub=’chinese’) t1 inner join (select </em> from t where sub=’english’) t2 on t1.name=t2.name where t1.name=’a’;</p>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/大数据/">大数据</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/hive-sql/">hive sql</a> <a class="tag-link" href="/tags/复习/">复习</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		1927
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/05/06/Hive sql/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/03/11/zookeeper原理/">zookeeper原理</a>  
	       
		 

		 <time>2018-03-11 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<p>Zookeeper中的角色主要有以下三类，如下表所示：</p>
<p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/zookeeper/zookeeper1.png" alt="7"></p>
<p>系统模型如图所示：</p>
<p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/zookeeper/zookeeper2.png" alt="1"></p>
<h2 id="1-2-设计目的"><a href="#1-2-设计目的" class="headerlink" title="1.2 设计目的"></a>1.2 设计目的</h2><p>1.最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。</p>
<p>2 .可靠性：具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。</p>
<p>3 .实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。</p>
<p>4 .等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。</p>
<p>5.原子性：更新只能成功或者失败，没有中间状态。</p>
<p>6 .顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。</p>
<h1 id="2-ZooKeeper的工作原理"><a href="#2-ZooKeeper的工作原理" class="headerlink" title="2 ZooKeeper的工作原理"></a>2 ZooKeeper的工作原理</h1><p>Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。</p>
<p>为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。</p>
<p>每个Server在工作过程中有三种状态：</p>
<ul>
<li>LOOKING：当前Server不知道leader是谁，正在搜寻</li>
<li>LEADING：当前Server即为选举出来的leader</li>
<li>FOLLOWING：leader已经选举出来，当前Server与之同步</li>
</ul>
<h2 id="2-1-选主流程"><a href="#2-1-选主流程" class="headerlink" title="2.1 选主流程"></a>2.1 选主流程</h2><p>当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。先介绍basic paxos流程：</p>
<ol>
<li>1 .选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；</li>
<li>2 .选举线程首先向所有Server发起一次询问(包括自己)；</li>
<li>3 .选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中；</li>
<li>\4.  收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；</li>
<li>\5.  线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。</li>
</ol>
<p>通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1.</p>
<p>每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示：</p>
<p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/zookeeper/zookeeper3.png" alt="2"></p>
<p>fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。其流程图如下所示：</p>
<p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/zookeeper/zookeeper4.png" alt="3"></p>
<h2 id="2-2-同步流程"><a href="#2-2-同步流程" class="headerlink" title="2.2 同步流程"></a>2.2 同步流程</h2><p>选完leader以后，zk就进入状态同步过程。</p>
<ol>
<li>\1. leader等待server连接；</li>
<li>2 .Follower连接leader，将最大的zxid发送给leader；</li>
<li>3 .Leader根据follower的zxid确定同步点；</li>
<li>4 .完成同步后通知follower 已经成为uptodate状态；</li>
<li>5 .Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。</li>
</ol>
<p>流程图如下所示：</p>
<p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/zookeeper/zookeeper5.png" alt="4"></p>
<h2 id="2-3-工作流程"><a href="#2-3-工作流程" class="headerlink" title="2.3 工作流程"></a>2.3 工作流程</h2><h3 id="2-3-1-Leader工作流程"><a href="#2-3-1-Leader工作流程" class="headerlink" title="2.3.1 Leader工作流程"></a>2.3.1 Leader工作流程</h3><p>Leader主要有三个功能：</p>
<ol>
<li>1 .恢复数据；</li>
<li>2 .维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型；</li>
<li>3 .Learner的消息类型主要有PING消息、REQUEST消息、ACK消息、REVALIDATE消息，根据不同的消息类型，进行不同的处理。</li>
</ol>
<p>PING消息是指Learner的心跳信息；REQUEST消息是Follower发送的提议信息，包括写请求及同步请求；ACK消息是Follower的对提议的回复，超过半数的Follower通过，则commit该提议；REVALIDATE消息是用来延长SESSION有效时间。<br>Leader的工作流程简图如下所示，在实际实现中，流程要比下图复杂得多，启动了三个线程来实现功能。<img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/zookeeper/zookeeper6.png" alt="5"></p>
<h3 id="2-3-2-Follower工作流程"><a href="#2-3-2-Follower工作流程" class="headerlink" title="2.3.2 Follower工作流程"></a>2.3.2 Follower工作流程</h3><p>Follower主要有四个功能：</p>
<ol>
<li>\1. 向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）；</li>
<li>2 .接收Leader消息并进行处理；</li>
<li>3 .接收Client的请求，如果为写请求，发送给Leader进行投票；</li>
<li>4 .返回Client结果。</li>
</ol>
<p>Follower的消息循环处理如下几种来自Leader的消息：</p>
<ol>
<li>1 .PING消息： 心跳消息；</li>
<li>2 .PROPOSAL消息：Leader发起的提案，要求Follower投票；</li>
<li>3 .COMMIT消息：服务器端最新一次提案的信息；</li>
<li>4 .UPTODATE消息：表明同步完成；</li>
<li>5 .REVALIDATE消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息；</li>
<li>6 .SYNC消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。</li>
</ol>
<p>Follower的工作流程简图如下所示，在实际实现中，Follower是通过5个线程来实现功能的。</p>
<p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/zookeeper/zookeeper7.png" alt="6"></p>
<p>对于observer的流程不再叙述，observer流程和Follower的唯一不同的地方就是observer不会参加leader发起的投票。</p>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/zookeeper/">zookeeper</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/zookeeper/">zookeeper</a> <a class="tag-link" href="/tags/复习/">复习</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		3024
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/03/11/zookeeper原理/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/03/11/spark架构/">spark架构</a>  
	       
		 

		 <time>2018-03-11 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<p>Apache Spark是一个围绕速度、易用性和复杂分析构建的大数据处理框架，最初在2009年由加州大学伯克利分校的AMPLab开发，并于2010年成为Apache的开源项目之一，与Hadoop和Storm等其他大数据和MapReduce技术相比，Spark有如下优势：</p>
<ul>
<li>Spark提供了一个全面、统一的框架用于管理各种有着不同性质（文本数据、图表数据等）的数据集和数据源（批量数据或实时的流数据）的大数据处理的需求</li>
<li><p>官方资料介绍Spark可以将Hadoop集群中的应用在内存中的运行速度提升100倍，甚至能够将应用在磁盘上的运行速度提升10倍</p>
<p><strong>目标：</strong></p>
</li>
<li><p>架构及生态</p>
</li>
<li>spark 与 hadoop</li>
<li>运行流程及特点</li>
<li>常用术语</li>
<li>standalone模式</li>
<li>yarn集群</li>
<li>RDD运行流程</li>
</ul>
<p><strong>架构及生态：</strong></p>
<hr>
<ul>
<li>通常当需要处理的数据量超过了单机尺度(比如我们的计算机有4GB的内存，而我们需要处理100GB以上的数据)这时我们可以选择spark集群进行计算，有时我们可能需要处理的数据量并不大，但是计算很复杂，需要大量的时间，这时我们也可以选择利用spark集群强大的计算资源，并行化地计算，其架构示意图如下：</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark1.png" alt="img"></li>
<li>Spark Core：包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都是构建在RDD和Spark Core之上的</li>
<li>Spark SQL：提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。</li>
<li>Spark Streaming：对实时数据流进行处理和控制。Spark Streaming允许程序能够像普通RDD一样处理实时数据</li>
<li>MLlib：一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，比如分类、回归等需要对大量数据集进行迭代的操作。</li>
<li>GraphX：控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、创建子图、访问路径上所有顶点的操作</li>
<li>Spark架构的组成图如下：</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark2.png" alt="img"></li>
<li>Cluster Manager：在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资源管理器</li>
<li>Worker节点：从节点，负责控制计算节点，启动Executor或者Driver。</li>
<li>Driver： 运行Application 的main()函数</li>
<li>Executor：执行器，是为某个Application运行在worker node上的一个进程</li>
</ul>
<p><strong>Spark与hadoop:</strong></p>
<hr>
<ul>
<li>Hadoop有两个核心模块，分布式存储模块HDFS和分布式计算模块Mapreduce</li>
<li>spark本身并没有提供分布式文件系统，因此spark的分析大多依赖于Hadoop的分布式文件系统HDFS</li>
<li>Hadoop的Mapreduce与spark都可以进行数据计算，而相比于Mapreduce，spark的速度更快并且提供的功能更加丰富</li>
<li>关系图如下：</li>
<li><p><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark3.png" alt="img"></p>
<p><strong>运行流程及特点：</strong></p>
</li>
</ul>
<hr>
<ul>
<li>spark运行流程图如下：</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark4.png" alt="img"></li>
</ul>
<ol>
<li>构建Spark Application的运行环境，启动SparkContext</li>
<li>SparkContext向资源管理器（可以是Standalone，Mesos，Yarn）申请运行Executor资源，并启动StandaloneExecutorbackend，</li>
<li>Executor向SparkContext申请Task</li>
<li>SparkContext将应用程序分发给Executor</li>
<li>SparkContext构建成DAG图，将DAG图分解成Stage、将Taskset发送给Task Scheduler，最后由Task Scheduler将Task发送给Executor运行</li>
<li>Task在Executor上运行，运行完释放所有资源</li>
</ol>
<p>​     <strong>Spark运行特点：</strong></p>
<ol>
<li>每个Application获取专属的executor进程，该进程在Application期间一直驻留，并以多线程方式运行Task。这种Application隔离机制是有优势的，无论是从调度角度看（每个Driver调度他自己的任务），还是从运行角度看（来自不同Application的Task运行在不同JVM中），当然这样意味着Spark Application不能跨应用程序共享数据，除非将数据写入外部存储系统</li>
<li>Spark与资源管理器无关，只要能够获取executor进程，并能保持相互通信就可以了</li>
<li>提交SparkContext的Client应该靠近Worker节点（运行Executor的节点），最好是在同一个Rack里，因为Spark Application运行过程中SparkContext和Executor之间有大量的信息交换</li>
<li>Task采用了数据本地性和推测执行的优化机制</li>
</ol>
<p><strong>常用术语:</strong></p>
<hr>
<ul>
<li><strong>Application:</strong> Appliction都是指用户编写的Spark应用程序，其中包括一个Driver功能的代码和分布在集群中多个节点上运行的Executor代码</li>
<li><strong>Driver:</strong>  Spark中的Driver即运行上述Application的main函数并创建SparkContext，创建SparkContext的目的是为了准备Spark应用程序的运行环境，在Spark中有SparkContext负责与ClusterManager通信，<em>进行资源申请、任务的分配和监控</em>等，当Executor部分运行完毕后，Driver同时负责将SparkContext关闭，通常用SparkContext代表Driver</li>
<li><strong>Executor:</strong>  某个Application运行在worker节点上的一个进程，  该进程负责运行某些Task， 并且负责将数据存到内存或磁盘上，每个Application都有各自独立的一批Executor， 在Spark on Yarn模式下，其进程名称为CoarseGrainedExecutor Backend。一个CoarseGrainedExecutor Backend有且仅有一个Executor对象， 负责将Task包装成taskRunner,并从线程池中抽取一个空闲线程运行Task， 这个每一个oarseGrainedExecutor Backend能并行运行Task的数量取决与分配给它的cpu个数</li>
<li><strong>Cluter Manager：</strong>指的是在集群上获取资源的外部服务。目前有三种类型</li>
</ul>
<ol>
<li><ol>
<li>Standalon : spark原生的资源管理，由Master负责资源的分配</li>
<li>Apache Mesos:与hadoop MR兼容性良好的一种资源调度框架</li>
<li>Hadoop Yarn: 主要是指Yarn中的ResourceManager</li>
</ol>
</li>
</ol>
<ul>
<li><strong>Worker:</strong> 集群中任何可以运行Application代码的节点，在Standalone模式中指的是通过slave文件配置的Worker节点，在Spark on Yarn模式下就是NoteManager节点</li>
<li><strong>Task:</strong> 被送到某个Executor上的工作单元，但hadoopMR中的MapTask和ReduceTask概念一样，是运行Application的基本单位，多个Task组成一个Stage，而Task的调度和管理等是由TaskScheduler负责</li>
<li><strong>Job:</strong> 包含多个Task组成的并行计算，往往由Spark Action触发生成， 一个Application中往往会产生多个Job</li>
<li><strong>Stage:</strong> 每个Job会被拆分成多组Task， 作为一个TaskSet， 其名称为Stage，Stage的划分和调度是有DAGScheduler来负责的，Stage有非最终的Stage（Shuffle Map Stage）和最终的Stage（Result Stage）两种，Stage的边界就是发生shuffle的地方</li>
<li><strong>DAGScheduler:</strong> 根据Job构建基于Stage的DAG（Directed Acyclic Graph有向无环图)，并提交Stage给TASkScheduler。 其划分Stage的依据是RDD之间的依赖的关系找出开销最小的调度方法，如下图</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark5.png" alt="img"></li>
<li><strong>TASKSedulter:</strong> 将TaskSET提交给worker运行，每个Executor运行什么Task就是在此处分配的. TaskScheduler维护所有TaskSet，当Executor向Driver发生心跳时，TaskScheduler会根据资源剩余情况分配相应的Task。另外TaskScheduler还维护着所有Task的运行标签，重试失败的Task。下图展示了TaskScheduler的作用</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark6.png" alt="img"></li>
<li>在不同运行模式中任务调度器具体为：</li>
</ul>
<ol>
<li><ol>
<li>Spark on Standalone模式为TaskScheduler</li>
<li>YARN-Client模式为YarnClientClusterScheduler</li>
<li>YARN-Cluster模式为YarnClusterScheduler</li>
</ol>
</li>
</ol>
<ul>
<li>将这些术语串起来的运行层次图如下：</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark7.png" alt="img"></li>
<li>Job=多个stage，Stage=多个同种task, Task分为ShuffleMapTask和ResultTask，Dependency分为ShuffleDependency和NarrowDependency</li>
</ul>
<p><strong>Spark运行模式：</strong></p>
<hr>
<ul>
<li>Spark的运行模式多种多样，灵活多变，部署在单机上时，既可以用本地模式运行，也可以用伪分布模式运行，而当以分布式集群的方式部署时，也有众多的运行模式可供选择，这取决于集群的实际情况，底层的资源调度即可以依赖外部资源调度框架，也可以使用Spark内建的Standalone模式。</li>
<li>对于外部资源调度框架的支持，目前的实现包括相对稳定的Mesos模式，以及hadoop YARN模式</li>
<li><strong>本地模式：</strong>常用于本地开发测试，本地还分别 local 和 local cluster</li>
</ul>
<p><strong>standalone:</strong> 独立集群运行模式</p>
<hr>
<ul>
<li>Standalone模式使用Spark自带的资源调度框架</li>
<li>采用Master/Slaves的典型架构，选用ZooKeeper来实现Master的HA</li>
<li>框架结构图如下:</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark8.png" alt="img"></li>
<li>该模式主要的节点有Client节点、Master节点和Worker节点。其中Driver既可以运行在Master节点上中，也可以运行在本地Client端。当用spark-shell交互式工具提交Spark的Job时，Driver在Master节点上运行；当使用spark-submit工具提交Job或者在Eclips、IDEA等开发平台上使用”new SparkConf.setManager(“spark://master:7077”)”方式运行Spark任务时，Driver是运行在本地Client端上的</li>
<li>运行过程如下图：（<em>参考至：<a href="http://blog.csdn.net/gamer_gyt/article/details/51833681" target="_blank" rel="noopener">http://blog.csdn.net/gamer_gyt/article/details/51833681</a></em>）</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark9.png" alt="img"></li>
</ul>
<ol>
<li>SparkContext连接到Master，向Master注册并申请资源（CPU Core 和Memory）</li>
<li>Master根据SparkContext的资源申请要求和Worker心跳周期内报告的信息决定在哪个Worker上分配资源，然后在该Worker上获取资源，然后启动StandaloneExecutorBackend；</li>
<li>StandaloneExecutorBackend向SparkContext注册；</li>
<li>SparkContext将Applicaiton代码发送给StandaloneExecutorBackend；并且SparkContext解析Applicaiton代码，构建DAG图，并提交给DAG Scheduler分解成Stage（当碰到Action操作时，就会催生Job；每个Job中含有1个或多个Stage，Stage一般在获取外部数据和shuffle之前产生），然后以Stage（或者称为TaskSet）提交给Task Scheduler，Task Scheduler负责将Task分配到相应的Worker，最后提交给StandaloneExecutorBackend执行；</li>
<li>StandaloneExecutorBackend会建立Executor线程池，开始执行Task，并向SparkContext报告，直至Task完成</li>
<li>所有Task完成后，SparkContext向Master注销，释放资源</li>
</ol>
<p><strong>yarn:</strong>  <em>（参考：<a href="http://blog.csdn.net/gamer_gyt/article/details/51833681）" target="_blank" rel="noopener">http://blog.csdn.net/gamer_gyt/article/details/51833681）</a></em></p>
<hr>
<ul>
<li>Spark on YARN模式根据Driver在集群中的位置分为两种模式：一种是YARN-Client模式，另一种是YARN-Cluster（或称为YARN-Standalone模式）</li>
<li>Yarn-Client模式中，Driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互，因为Driver在客户端，所以可以通过webUI访问Driver的状态，默认是<a href="http://hadoop1:4040访问，而YARN通过http://" target="_blank" rel="noopener">http://hadoop1:4040访问，而YARN通过http://</a> hadoop1:8088访问</li>
<li>YARN-client的工作流程步骤为：</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark10.png" alt="img"></li>
<li>Spark Yarn Client向YARN的ResourceManager申请启动Application Master。同时在SparkContent初始化中将创建DAGScheduler和TASKScheduler等，由于我们选择的是Yarn-Client模式，程序会选择YarnClientClusterScheduler和YarnClientSchedulerBackend</li>
<li>ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派</li>
<li>Client中的SparkContext初始化完毕后，与ApplicationMaster建立通讯，向ResourceManager注册，根据任务信息向ResourceManager申请资源（Container）</li>
<li>一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向Client中的SparkContext注册并申请Task</li>
<li>client中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向Driver汇报运行的状态和进度，以让Client随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务</li>
<li>应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己</li>
</ul>
<p><strong>Spark Cluster模式:</strong></p>
<ul>
<li>在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：</li>
</ul>
<ol>
<li><ol>
<li>第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；</li>
<li>第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成</li>
</ol>
</li>
</ol>
<ul>
<li>YARN-cluster的工作流程分为以下几个步骤</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark11.png" alt="img"></li>
<li>Spark Yarn Client向YARN中提交应用程序，包括ApplicationMaster程序、启动ApplicationMaster的命令、需要在Executor中运行的程序等</li>
<li>ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，其中ApplicationMaster进行SparkContext等的初始化</li>
<li>ApplicationMaster向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将采用轮询的方式通过RPC协议为各个任务申请资源，并监控它们的运行状态直到运行结束</li>
<li>一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向ApplicationMaster中的SparkContext注册并申请Task。这一点和Standalone模式一样，只不过SparkContext在Spark Application中初始化时，使用CoarseGrainedSchedulerBackend配合YarnClusterScheduler进行任务的调度，其中YarnClusterScheduler只是对TaskSchedulerImpl的一个简单包装，增加了对Executor的等待逻辑等</li>
<li>ApplicationMaster中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向ApplicationMaster汇报运行的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务</li>
<li>应用程序运行完成后，ApplicationMaster向ResourceManager申请注销并关闭自己</li>
</ul>
<p><strong>Spark Client 和 Spark Cluster的区别:</strong></p>
<ul>
<li>理解YARN-Client和YARN-Cluster深层次的区别之前先清楚一个概念：Application Master。在YARN中，每个Application实例都有一个ApplicationMaster进程，它是Application启动的第一个容器。它负责和ResourceManager打交道并请求资源，获取资源之后告诉NodeManager为其启动Container。从深层次的含义讲YARN-Cluster和YARN-Client模式的区别其实就是ApplicationMaster进程的区别</li>
<li>YARN-Cluster模式下，Driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业</li>
<li>YARN-Client模式下，Application Master仅仅向YARN请求Executor，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开</li>
</ul>
<p>思考： 我们在使用Spark提交job时使用的哪种模式？</p>
<p><strong>RDD运行流程：</strong></p>
<hr>
<ul>
<li>RDD在Spark中运行大概分为以下三步：</li>
</ul>
<ol>
<li><ol>
<li>创建RDD对象</li>
<li>DAGScheduler模块介入运算，计算RDD之间的依赖关系，RDD之间的依赖关系就形成了DAG</li>
<li>每一个Job被分为多个Stage。划分Stage的一个主要依据是当前计算因子的输入是否是确定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销</li>
</ol>
</li>
</ol>
<ul>
<li>示例图如下：</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark12.png" alt="img"></li>
<li>以下面一个按 A-Z 首字母分类，查找相同首字母下不同姓名总个数的例子来看一下 RDD 是如何运行起来的</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark13.png" alt="img"></li>
<li>创建 RDD  上面的例子除去最后一个 collect 是个动作，不会创建 RDD 之外，前面四个转换都会创建出新的 RDD 。因此第一步就是创建好所有 RDD( 内部的五项信息 )？</li>
<li>创建执行计划 Spark 会尽可能地管道化，并基于是否要重新组织数据来划分 阶段 (stage) ，例如本例中的 groupBy() 转换就会将整个执行计划划分成两阶段执行。最终会产生一个 DAG(directed acyclic graph ，有向无环图 ) 作为逻辑执行计划</li>
<li><img src="https://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/spark/spark14.png" alt="img"></li>
<li>调度任务  将各阶段划分成不同的 任务 (task) ，每个任务都是数据和计算的合体。在进行下一阶段前，当前阶段的所有任务都要执行完成。因为下一阶段的第一个转换一定是重新组织数据的，所以必须等当前阶段所有结果数据都计算出来了才能继续</li>
</ul>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/spark/">spark</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/spark/">spark</a> <a class="tag-link" href="/tags/复习/">复习</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		8611
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/03/11/spark架构/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/02/12/idea操作/">idea操作</a>  
	       
		 

		 <time>2018-02-12 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<h1 id="1-idea操作"><a href="#1-idea操作" class="headerlink" title="1 idea操作"></a>1 idea操作</h1><h2 id="设置idea的eclipse模式的快捷键"><a href="#设置idea的eclipse模式的快捷键" class="headerlink" title="设置idea的eclipse模式的快捷键"></a>设置idea的eclipse模式的快捷键</h2><p>windows:Configure-&gt;setting-&gt;keymap-&gt;keymaps-&gt;eclipse<br>Mac:Configure-&gt;preferences-&gt;keymap-&gt;keymaps-&gt;eclipse(Mac OS X)<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/idea/idea1.gif" alt="idea1"></p>
<h2 id="设置idea的maven打包"><a href="#设置idea的maven打包" class="headerlink" title="设置idea的maven打包"></a>设置idea的maven打包</h2><p><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/idea/idea2.gif" alt="idea2"></p>
<h2 id="创建idea的web项目"><a href="#创建idea的web项目" class="headerlink" title="创建idea的web项目"></a>创建idea的web项目</h2><p><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/idea/idea3.gif" alt="idea3"><br> 创建的项目没法创建Java类，需要右键项目-&gt;Mark Directoys-&gt;sources root<br><a href="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/video/idea/idea.avi" target="_blank" rel="noopener">idea操作完整视频下载</a></p>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/java/">java</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/java/">java</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		259
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/02/12/idea操作/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/02/10/IDEA中pom常见错误及解决方法/">IDEA中pom常见错误及解决方法</a>  
	       
		 

		 <time>2018-02-10 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<h1 id="1-inspects-a-maven-model-for-resolution-problems"><a href="#1-inspects-a-maven-model-for-resolution-problems" class="headerlink" title="1 inspects a maven model for resolution problems"></a>1 inspects a maven model for resolution problems</h1><h2 id="第一种-找到pom-xml"><a href="#第一种-找到pom-xml" class="headerlink" title="第一种   找到pom.xml"></a>第一种   找到pom.xml</h2><pre><code>右击  --&gt; Maven --&gt; reImport
</code></pre><h2 id="第二种-查看jar包是否下载正确"><a href="#第二种-查看jar包是否下载正确" class="headerlink" title="第二种 查看jar包是否下载正确"></a>第二种 查看jar包是否下载正确</h2> 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/java/">java</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/java/">java</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		96
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/02/10/IDEA中pom常见错误及解决方法/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/02/05/solr cloud安装部署/">solr cloud安装部署</a>  
	       
		 

		 <time>2018-02-05 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<h1 id="第一部分：初始化环境"><a href="#第一部分：初始化环境" class="headerlink" title="第一部分：初始化环境"></a>第一部分：初始化环境</h1><h2 id="1、初始化环境"><a href="#1、初始化环境" class="headerlink" title="1、初始化环境"></a>1、初始化环境</h2><ul>
<li>准备三台linux服务器</li>
<li>在服务器上创建三个目录<ul>
<li>software目录:software目录是用来存放软件安装包<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /<span class="keyword">export</span>/software</span><br></pre></td></tr></table></figure></li>
<li>servers目录：servers目录用来用来安装软件<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /<span class="keyword">export</span>/servers</span><br></pre></td></tr></table></figure></li>
<li>data目录：data目录用来存放软件运行的数据、日志<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /<span class="keyword">export</span>/data</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>关闭三台机器的防火墙<ul>
<li>永久关闭，需要重启<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure></li>
<li>临时管理，重启失效<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br></pre></td></tr></table></figure></li>
<li>关闭之后可查看防火墙状态<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service iptables status</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h2 id="2、准备solr安装包"><a href="#2、准备solr安装包" class="headerlink" title="2、准备solr安装包"></a>2、准备solr安装包</h2><ul>
<li>上传solr-4.10.2的安装包 到 /export/software 目录</li>
<li>上传 tomcat-</li>
</ul>
<h2 id="3、解压安装包"><a href="#3、解压安装包" class="headerlink" title="3、解压安装包"></a>3、解压安装包</h2><ul>
<li>解压solr<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf solr<span class="number">-4.10</span><span class="number">.2</span>.tgz -C /<span class="keyword">export</span>/servers/servers/</span><br></pre></td></tr></table></figure></li>
<li>解压 tomcat<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-tomcat<span class="number">-7.0</span><span class="number">.57</span>.tar.gz -C /<span class="keyword">export</span>/servers/</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="4、创建solr的工作目录"><a href="#4、创建solr的工作目录" class="headerlink" title="4、创建solr的工作目录"></a>4、创建solr的工作目录</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /<span class="keyword">export</span>/data/solr_home</span><br></pre></td></tr></table></figure>
<h2 id="5、tomcat-软连接创建"><a href="#5、tomcat-软连接创建" class="headerlink" title="5、tomcat 软连接创建"></a>5、tomcat 软连接创建</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s apache-tomcat<span class="number">-7.0</span><span class="number">.57</span>/ tomcat4solr</span><br></pre></td></tr></table></figure>
<h1 id="第二部分：在Linux上部署单机版本的solr"><a href="#第二部分：在Linux上部署单机版本的solr" class="headerlink" title="第二部分：在Linux上部署单机版本的solr"></a>第二部分：在Linux上部署单机版本的solr</h1><h2 id="1、将solr-war包拷贝到tomcat的webapps下"><a href="#1、将solr-war包拷贝到tomcat的webapps下" class="headerlink" title="1、将solr.war包拷贝到tomcat的webapps下"></a>1、将solr.war包拷贝到tomcat的webapps下</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/solr<span class="number">-4.10</span><span class="number">.2</span>/example/webapps</span><br><span class="line">cp solr.war /<span class="keyword">export</span>/servers/tomcat4solr/webapps/</span><br></pre></td></tr></table></figure>
<h2 id="2、启动下tomcat，让tomcat帮解压solr-war，然后关闭tomcat"><a href="#2、启动下tomcat，让tomcat帮解压solr-war，然后关闭tomcat" class="headerlink" title="2、启动下tomcat，让tomcat帮解压solr.war，然后关闭tomcat"></a>2、启动下tomcat，让tomcat帮解压solr.war，然后关闭tomcat</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/bin/</span><br><span class="line">./startup.sh </span><br><span class="line">./shutdown.sh</span><br></pre></td></tr></table></figure>
<h2 id="3、修改solr-web项目的配置文件，指定solrhome"><a href="#3、修改solr-web项目的配置文件，指定solrhome" class="headerlink" title="3、修改solr web项目的配置文件，指定solrhome"></a>3、修改solr web项目的配置文件，指定solrhome</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/webapps/solr/WEB-INF/</span><br><span class="line">vi web.xml</span><br></pre></td></tr></table></figure>
<p>修改内容,并保存。<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solrhome.png" alt="solrhome"></p>
<ul>
<li>第一步 去掉注释</li>
<li>第二步 修改 env-entry-type 为 /export/data/solr_home</li>
</ul>
<h2 id="4、拷贝一个solr-core到solr-home下"><a href="#4、拷贝一个solr-core到solr-home下" class="headerlink" title="4、拷贝一个solr core到solr_home下"></a>4、拷贝一个solr core到solr_home下</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/solr<span class="number">-4.10</span><span class="number">.2</span>/example/solr</span><br><span class="line">cp -r collection1/ /<span class="keyword">export</span>/data/solr_home/</span><br></pre></td></tr></table></figure>
<h2 id="5、为solr的运行准备配置lib"><a href="#5、为solr的运行准备配置lib" class="headerlink" title="5、为solr的运行准备配置lib"></a>5、为solr的运行准备配置lib</h2><ul>
<li>先创建lib目录<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/data/solr_home/</span><br><span class="line">mkdir lib</span><br></pre></td></tr></table></figure></li>
<li>然后将依赖拷贝过来<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd lib/</span><br><span class="line">cp -r /<span class="keyword">export</span>/servers/solr<span class="number">-4.10</span><span class="number">.2</span>/contrib/ .</span><br><span class="line">cp -r /<span class="keyword">export</span>/servers/solr<span class="number">-4.10</span><span class="number">.2</span>/dist/ .</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="6、修改collection1-的solrconfig-xml文件，配置lib路径"><a href="#6、修改collection1-的solrconfig-xml文件，配置lib路径" class="headerlink" title="6、修改collection1 的solrconfig.xml文件，配置lib路径"></a>6、修改collection1 的solrconfig.xml文件，配置lib路径</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/data/solr_home/collection1/conf</span><br><span class="line">vi solrconfig.xml</span><br></pre></td></tr></table></figure>
<ul>
<li>原始内容<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solrconfig1.png" alt="solrconfig1"></li>
<li>修改后的内容<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solrconfig2.png" alt="solrconfig2"></li>
</ul>
<h2 id="7、将ext扩展的jar包拷贝到solr的web项目下"><a href="#7、将ext扩展的jar包拷贝到solr的web项目下" class="headerlink" title="7、将ext扩展的jar包拷贝到solr的web项目下"></a>7、将ext扩展的jar包拷贝到solr的web项目下</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/webapps/solr/WEB-INF/lib/</span><br><span class="line">cp -r /<span class="keyword">export</span>/servers/solr<span class="number">-4.10</span><span class="number">.2</span>/example/lib/ext<span class="comment">/* .</span></span><br></pre></td></tr></table></figure>
<h2 id="8、启动solr"><a href="#8、启动solr" class="headerlink" title="8、启动solr"></a>8、启动solr</h2><p>启动solr即使启动tomcat<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/bin</span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure></p>
<h2 id="9、访问单机版本的solr服务"><a href="#9、访问单机版本的solr服务" class="headerlink" title="9、访问单机版本的solr服务"></a>9、访问单机版本的solr服务</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:<span class="comment">//&#123;u solr hostname&#125;:8080/solr</span></span><br></pre></td></tr></table></figure>
<h1 id="第三部分-配置集群"><a href="#第三部分-配置集群" class="headerlink" title="第三部分:配置集群"></a>第三部分:配置集群</h1><h2 id="1、梳理修改了哪些目录"><a href="#1、梳理修改了哪些目录" class="headerlink" title="1、梳理修改了哪些目录"></a>1、梳理修改了哪些目录</h2><ul>
<li>三个标准目录<ul>
<li>/export/data/</li>
<li>/export/servers/</li>
<li>/export/software/</li>
</ul>
</li>
<li>安装目录<ul>
<li>/export/data/solr_home</li>
<li>/export/servers/tomcat4solr<br>总结，需要将两个solr的安装目录拷贝到其他机器上。</li>
</ul>
</li>
</ul>
<h2 id="2、在其他机器上创建工作目录"><a href="#2、在其他机器上创建工作目录" class="headerlink" title="2、在其他机器上创建工作目录"></a>2、在其他机器上创建工作目录</h2><p>在hadoop02上操作<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /<span class="keyword">export</span>/data/solr_home</span><br><span class="line">mkdir -p /<span class="keyword">export</span>/servers/tomcat4solr</span><br></pre></td></tr></table></figure><br>在hadoop03上操作<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /<span class="keyword">export</span>/data/solr_home</span><br><span class="line">mkdir -p /<span class="keyword">export</span>/servers/tomcat4solr</span><br></pre></td></tr></table></figure></p>
<h2 id="3、拷贝安装内容到其它机器"><a href="#3、拷贝安装内容到其它机器" class="headerlink" title="3、拷贝安装内容到其它机器"></a>3、拷贝安装内容到其它机器</h2><p>在hadoop01上执行<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scp -r /<span class="keyword">export</span>/data/solr_home<span class="comment">/* hadoop02:/export/data/solr_home/</span></span><br><span class="line"><span class="comment">scp -r /export/servers/tomcat4solr/* hadoop02:/export/servers/tomcat4solr/</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">scp -r /export/data/solr_home/* hadoop03:/export/data/solr_home/</span></span><br><span class="line"><span class="comment">scp -r /export/servers/tomcat4solr/* hadoop03:/export/servers/tomcat4solr/</span></span><br></pre></td></tr></table></figure></p>
<h2 id="4、启动zookeeper集群"><a href="#4、启动zookeeper集群" class="headerlink" title="4、启动zookeeper集群"></a>4、启动zookeeper集群</h2><h2 id="5、将solr的配置文件上传到zookeeper"><a href="#5、将solr的配置文件上传到zookeeper" class="headerlink" title="5、将solr的配置文件上传到zookeeper"></a>5、将solr的配置文件上传到zookeeper</h2><p>主要是solrconfig.xml和scheme.xml、<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/<span class="keyword">export</span>/servers/solr<span class="number">-4.10</span><span class="number">.2</span>/example/scripts/cloud-scripts</span><br><span class="line"></span><br><span class="line">./zkcli.sh -zkhost zk01:<span class="number">2181</span>,zk02:<span class="number">2181</span>,zk03:<span class="number">2181</span> -cmd upconfig -confdir /<span class="keyword">export</span>/data/solr_home/collection1/conf/ -confname solrconf</span><br></pre></td></tr></table></figure></p>
<h2 id="6、检查配置文件是否上传到zookeeper上"><a href="#6、检查配置文件是否上传到zookeeper上" class="headerlink" title="6、检查配置文件是否上传到zookeeper上"></a>6、检查配置文件是否上传到zookeeper上</h2><p>使用zookeeper的客户端命令查看zookeeper的目录树<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkCli.sh</span><br></pre></td></tr></table></figure><br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/zkcli.png" alt="zkcli"><br>也可以使用zookeeper可视化工具查看</p>
<h2 id="7、修改集群中每个solr的solr-xml文件"><a href="#7、修改集群中每个solr的solr-xml文件" class="headerlink" title="7、修改集群中每个solr的solr.xml文件"></a>7、修改集群中每个solr的solr.xml文件</h2><ul>
<li>修改配置文件<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp /<span class="keyword">export</span>/servers/solr<span class="number">-4.10</span><span class="number">.2</span>/example/solr/solr.xml /<span class="keyword">export</span>/data/solr_home/</span><br><span class="line">cd /<span class="keyword">export</span>/data/solr_home/</span><br><span class="line">vi solr.xml</span><br></pre></td></tr></table></figure>
<img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solr.png" alt="solr"></li>
<li>发送给其他节点<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp solr.xml hadoop02:$PWD</span><br><span class="line">scp solr.xml hadoop03:$PWD</span><br></pre></td></tr></table></figure>
<h2 id="8、让solr和zookeeper产生关系"><a href="#8、让solr和zookeeper产生关系" class="headerlink" title="8、让solr和zookeeper产生关系"></a>8、让solr和zookeeper产生关系</h2>修改每一台solr的tomcat 的 bin目录下catalina.sh文件中加入DzkHost指定zookeeper服务器地址。<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/bin</span><br><span class="line">vi catalina.sh</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> JAVA_OPTS=<span class="string">"-DzkHost=zk01:2181,zk02:2181,zk03:2181"</span></span><br></pre></td></tr></table></figure>
<img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solr_zookeeper.png" alt="solr_zookeeper"><br>然后分发到到其它机器上<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp catalina.sh hadoop02:$PWD</span><br><span class="line">scp catalina.sh hadoop03:$PWD</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="9、依次启动tomcat"><a href="#9、依次启动tomcat" class="headerlink" title="9、依次启动tomcat"></a>9、依次启动tomcat</h2><p>在hadoop01上<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/bin</span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure><br>在hadoop02上<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/bin</span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure><br>在hadoop03上<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /<span class="keyword">export</span>/servers/tomcat4solr/bin</span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure><br>然后访问任意一台solr服务，可以看到集群配置成功。<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solr_ui.png" alt="solr_ui"></p>
<h1 id="第四部分：配置新的集群"><a href="#第四部分：配置新的集群" class="headerlink" title="第四部分：配置新的集群"></a>第四部分：配置新的集群</h1><h2 id="1、配置命令"><a href="#1、配置命令" class="headerlink" title="1、配置命令"></a>1、配置命令</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:<span class="comment">//hadoop01:8080/solr/admin/collections?action=CREATE&amp;name=mycore2&amp;numShards=2&amp;replicationFactor=2&amp;maxShardsPerNode=8&amp;property.schema=schema.xml&amp;property.config=solrconfig.xml</span></span><br></pre></td></tr></table></figure>
<h2 id="2、命令说明"><a href="#2、命令说明" class="headerlink" title="2、命令说明"></a>2、命令说明</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">name指明collection名称</span><br><span class="line">numShards指明分片数</span><br><span class="line">replicationFactor指明副本数</span><br><span class="line">maxShardsPerNode 每个节点最大分片数（默认为<span class="number">1</span>）</span><br><span class="line">property.schema：指定使用的schema.xml，这个文件必须在zookeeper上。</span><br><span class="line">property.config：指定使用的solrconfig.xml，这个文件必须在zookeeper上。</span><br></pre></td></tr></table></figure>
<h2 id="3、执行效果"><a href="#3、执行效果" class="headerlink" title="3、执行效果"></a>3、执行效果</h2><p><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solr_ui1.png" alt="solr_ui1"><br>查看cloud管理界面：<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/solr/solr_ui2.png" alt="solr_ui2"></p>
<h2 id="4、其他可选操作"><a href="#4、其他可选操作" class="headerlink" title="4、其他可选操作"></a>4、其他可选操作</h2><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">删除core命令；</span><br><span class="line">http:<span class="comment">//node01:8080/solr/admin/collections?action=DELETE&amp;name=collection1</span></span><br><span class="line">执行后原来的collection1删除，如下：</span><br><span class="line"></span><br><span class="line">查询所有的core</span><br><span class="line">http:<span class="comment">//node01:8080/solr/admin/collections?action=LIST</span></span><br><span class="line"></span><br><span class="line">显示集群的状态</span><br><span class="line">http:<span class="comment">//node01:8080/solr/admin/collections?action=CLUSTERSTATUS</span></span><br><span class="line"></span><br><span class="line">分裂shard</span><br><span class="line">http:<span class="comment">//node01:8080/solr/admin/collections?action=SPLITSHARD&amp;collection=mycore9&amp;shard=shard1</span></span><br><span class="line"></span><br><span class="line">删除shard</span><br><span class="line">http:<span class="comment">//node01:8080/solr/admin/collections?action=DELETESHARD&amp;shard=shard1&amp;collection=mycore9</span></span><br></pre></td></tr></table></figure>
<h1 id="第五部分：使用Java-Api操作集群"><a href="#第五部分：使用Java-Api操作集群" class="headerlink" title="第五部分：使用Java Api操作集群"></a>第五部分：使用Java Api操作集群</h1><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.apache.solr&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;4.10.2&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">     &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;commons-logging&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;commons-logging-api&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.1&lt;/version&gt;</span><br><span class="line">    &lt;/dependency&gt;</span><br><span class="line">&lt;/dependencies&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">package cn.itcast.ss.solr;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">import org.apache.solr.client.solrj.SolrQuery;</span><br><span class="line">import org.apache.solr.client.solrj.SolrServerException;</span><br><span class="line">import org.apache.solr.client.solrj.impl.CloudSolrServer;</span><br><span class="line">import org.apache.solr.client.solrj.response.QueryResponse;</span><br><span class="line">import org.apache.solr.common.SolrInputDocument;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * solrcloud 操作和solr的操作基本一样</span></span><br><span class="line"><span class="comment"> * 唯一不同的是，solr创建是httpsolrserver，solr cloud创建是cloudsolrserver</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">public <span class="keyword">class</span> SolrCloudTest &#123;</span><br><span class="line">	</span><br><span class="line">	public <span class="keyword">static</span> <span class="keyword">void</span> main(String[] args) throws Exception &#123;</span><br><span class="line">		<span class="comment">// 1.创建一个solr cloud的连接，需要指定zookeeper的地址，需要制定操作的索引库</span></span><br><span class="line">		CloudSolrServer cloudSolrServer = new CloudSolrServer(<span class="string">"zk01:2181,zk02:2181,zk03:2181"</span>);</span><br><span class="line">		cloudSolrServer.setDefaultCollection(<span class="string">"aaa"</span>);</span><br><span class="line">		cloudSolrServer.connect();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2.创建索引</span></span><br><span class="line">		SolrInputDocument solrInputDocument = new SolrInputDocument();</span><br><span class="line">		solrInputDocument.addField(<span class="string">"id"</span>, <span class="string">"300"</span>);</span><br><span class="line">		solrInputDocument.addField(<span class="string">"name"</span>, <span class="string">"我爱我的祖国"</span>);</span><br><span class="line">		solrInputDocument.addField(<span class="string">"price"</span>, <span class="string">"520"</span>);</span><br><span class="line">		solrInputDocument.addField(<span class="string">"url"</span>, <span class="string">"http://www.itcast.cn"</span>);</span><br><span class="line">		cloudSolrServer.add(solrInputDocument);</span><br><span class="line">		cloudSolrServer.commit();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3.查询代码</span></span><br><span class="line">		SolrQuery solrQuery = new SolrQuery(<span class="string">"name:祖国"</span>);</span><br><span class="line">		QueryResponse res = cloudSolrServer.query(solrQuery);</span><br><span class="line">		List&lt;Product&gt; beans = res.getBeans(Product.class);</span><br><span class="line">		<span class="keyword">for</span> (Product product : beans) &#123;</span><br><span class="line">			System.out.println(product);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 4.删除文档</span></span><br><span class="line"><span class="comment">//		cloudSolrServer.deleteById("100");</span></span><br><span class="line">		cloudSolrServer.deleteByQuery(<span class="string">"name:祖国"</span>);</span><br><span class="line">		cloudSolrServer.commit();</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 收尾工作-关闭连接</span></span><br><span class="line">		cloudSolrServer.shutdown();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/java/">java</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/solr/">solr</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		6187
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/02/05/solr cloud安装部署/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/02/02/使用spark-sql操作hive中的表/">使用spark-sql操作hive中的表</a>  
	       
		 

		 <time>2018-02-02 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<h1 id="SparkSQL操作Hive中的表数据"><a href="#SparkSQL操作Hive中的表数据" class="headerlink" title="SparkSQL操作Hive中的表数据"></a>SparkSQL操作Hive中的表数据</h1><p>spark可以通过读取hive的元数据来兼容hive，读取hive的表数据，然后在spark引擎中进行sql统计分析。<br>注意：hive表的字符集应为latin1</p>
<h1 id="1、启动hive的元数据服务"><a href="#1、启动hive的元数据服务" class="headerlink" title="1、启动hive的元数据服务"></a>1、启动hive的元数据服务</h1><p>hive可以通过服务的形式对外提供元数据读写操作，通过简单的配置即可<br>编辑 $HIVE_HOME/conf/hive-site.xml,增加如下内容:<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="line">&lt;value&gt;thrift:<span class="comment">//master:9083&lt;/value&gt;</span></span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><br> 启动hive metastore<br>[hadoop@centos-linux-7  ~]${HIVE_HOME}/bin/hive –service metastore  1&gt;/dev/null  2&gt;&amp;1  &amp;</p>
<p> 查看 metastore:<br>[hadoop@centos-linux-7  ~] jobs<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/%E5%90%AF%E5%8A%A8megastore.png" alt="启动megastore"></p>
<h1 id="2、spark配置"><a href="#2、spark配置" class="headerlink" title="2、spark配置"></a>2、spark配置</h1><p>将hive的配置文件拷贝给spark<br>将 $HIVE_HOME/conf/hive-site.xml copy $SPARK_HOME/conf/<br>将mysql的jdbc驱动包拷贝给spark<br>将 $HIVE_HOME/lib/mysql-connector-java-5.1.12.jar copy或者软链到$SPARK_HOME/lib/</p>
<h1 id="3-启动spark-sql"><a href="#3-启动spark-sql" class="headerlink" title="3.启动spark-sql"></a>3.启动spark-sql</h1><p>所有命令启动spark-sql<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-sql --master spark:<span class="comment">//master:7077</span></span><br></pre></td></tr></table></figure><br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A51.png" alt="启动spark-sql"><br>现在可以尽情的操作hive了，<br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C1.png" alt="查询语句1"><br><img src="http://mrblogimgs.oss-cn-qingdao.aliyuncs.com/img/hive/%E6%9F%A5%E8%AF%A2%E7%BB%93%E6%9E%9C1.png" alt="查询结果1"></p>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/大数据/">大数据</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/spark/">spark</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		717
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/02/02/使用spark-sql操作hive中的表/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/01/25/tomcat版本约束/">tomcat版本约束</a>  
	       
		 

		 <time>2018-01-25 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<h1 id="tomcat版本约束"><a href="#tomcat版本约束" class="headerlink" title="tomcat版本约束"></a>tomcat版本约束</h1><table>
<thead>
<tr>
<th>Servlet约束</th>
<th>JSP约束</th>
<th>EL约束</th>
<th style="text-align:center">WebSocket约束</th>
<th style="text-align:center">JASPIC约束</th>
<th style="text-align:center">Apache Tomcat版本</th>
<th style="text-align:center">Tomcat最新发布的版本</th>
<th style="text-align:center">支持的Java版本</th>
</tr>
</thead>
<tbody>
<tr>
<td>4.0</td>
<td>2.3</td>
<td>3.0.</td>
<td style="text-align:center">1.1.</td>
<td style="text-align:center">1.1.</td>
<td style="text-align:center">9.0.x</td>
<td style="text-align:center">9.0.2(测试版)</td>
<td style="text-align:center">8 and later</td>
</tr>
<tr>
<td>3.1</td>
<td>2.3</td>
<td>3.0.</td>
<td style="text-align:center">1.1.</td>
<td style="text-align:center">1.1.</td>
<td style="text-align:center">8.5.x</td>
<td style="text-align:center">8.5.24</td>
<td style="text-align:center">7 and later</td>
</tr>
<tr>
<td>3.1</td>
<td>2.3</td>
<td>3.0.</td>
<td style="text-align:center">1.1.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">8.0.x(已废弃)</td>
<td style="text-align:center">8.0.48(已废弃)</td>
<td style="text-align:center">7 and later</td>
</tr>
<tr>
<td>3.0</td>
<td>2.2</td>
<td>2.2.</td>
<td style="text-align:center">1.1.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">7.0.x</td>
<td style="text-align:center">7.0.82</td>
<td style="text-align:center">6 and later(7 and later for WebSocket)</td>
</tr>
<tr>
<td>2.5</td>
<td>2.1</td>
<td>2.1.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">6.0.x(已归档)</td>
<td style="text-align:center">6.0.53(已归档)</td>
<td style="text-align:center">5 and later</td>
</tr>
<tr>
<td>2.4</td>
<td>2.0</td>
<td>N/A.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">5.5.x(已归档)</td>
<td style="text-align:center">5.5.36(已归档)</td>
<td style="text-align:center">1.4 and later</td>
</tr>
<tr>
<td>2.3</td>
<td>1.2</td>
<td>N/A.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">4.1.x(已归档)</td>
<td style="text-align:center">4.1.40(已归档)</td>
<td style="text-align:center">1.3 and later</td>
</tr>
<tr>
<td>2.2</td>
<td>1.1</td>
<td>N/A.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">N/A.</td>
<td style="text-align:center">3.3.x(已归档)</td>
<td style="text-align:center">3.3.2(已归档)</td>
<td style="text-align:center">1.1 and later</td>
</tr>
</tbody>
</table>
<p>⚠️所有已废弃，已归档和测试版的tomcat不建议下载      </p>
 

	    
</div>

<div class="center">
				

			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		593
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/01/25/tomcat版本约束/">阅读更多</a> 
    	
</article>     
     	
      	  	

  		
    	<article class="article">		
	   
	<div class="article-header">
	    
	     <a class="article-title"  href="/2018/01/08/spark资料转载/">spark资料转载</a>  
	       
		 

		 <time>2018-01-08 </time>    
	</div>


    <div class="article-excerpt">	
	
  	

	  

	  	<h1 id="大数据资料转载"><a href="#大数据资料转载" class="headerlink" title="大数据资料转载"></a>大数据资料转载</h1><p><a href="http://spark.apachecn.org/docs/cn/2.2.0/index.html" target="_blank" rel="noopener">spark中文官网</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1005705?fromSource=gwzcw.700962.700962.700962" target="_blank" rel="noopener">Spark MLlib 算法系列之 FM</a></p>
<p><a href="http://shujuren.org/article/420.html" target="_blank" rel="noopener">大数据框架对比：Hadoop、Storm、Samza、Spark和Flink</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1030060" target="_blank" rel="noopener">大数据奇葩说：盘点10个有趣的大数据</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1030050" target="_blank" rel="noopener">大数据实时推荐-不只是统计</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1004886" target="_blank" rel="noopener">Spark Cache 性能测试</a></p>
 

	    
</div>

<div class="center">
			

				<span class="post-meta">		
				<span class="iconfont icon-category"></span>
				<a class="category-link" href="/categories/资料转载/">资料转载</a>
				</span>
		
			

		
				
				<span class="post-meta">
				<span class="iconfont icon-tag"></span>
				<a class="tag-link" href="/tags/Hadoop/">Hadoop</a> <a class="tag-link" href="/tags/spark/">spark</a> <a class="tag-link" href="/tags/资料转载/">资料转载</a>
				</span>			
			


		

		<span class="post-words"><span class="iconfont icon-words"></span>
		122
		</span>		
</div>		

		
    <a class="article-readmore" href="/2018/01/08/spark资料转载/">阅读更多</a> 
    	
</article>     
     	
  

 

  <nav class="paginator">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
  </nav>
  

</section> 

    </div>        

    
    <div class="mask"> </div>
    <div class="back-to-top iconfont icon-backtotop fadeIn"></div> 

    


<script src="/js/search.js"></script>     
          
          <div class="search-container sildeUpMin">
            <input type="text" placeholder="输入你想搜索的" id="search-input" class="search-input">  
              <span class="search-cancel iconfont icon-cancel"></span>
              <div id="search-result" class="search-result"></div>
          </div>
 

     <div class="mobile-menu">      

      
      <img class="mobile-menu-icon no-gallery" src= /img/favicon.png >   
      

         
            

            <a class="mobile-menu-link" href="/">首页
            </a>
            
         
            

            <a class="mobile-menu-link" href="/archives">归档
            </a>
            
         
            

            <a class="mobile-menu-link" href="/categories">分类
            </a>
            
         
            

            <a class="mobile-menu-link" href="/tags">标签
            </a>
            
         
            

            <a class="mobile-menu-link" href="/about">关于
            </a>
            
         
                          

            <a class="mobile-menu-link mobile-menu-search" href="#">搜索 </a>                 
            
         
</div>     
    

<footer id="footer">
	   
   	 <div>	
	   	    	
   	 </div>
   
   	 
	 <div>
	 	&copy;
		2018
		Rui Min	 

	 </div>


   
   	 <div>
	
	 <a href="http://hexo.io/" target="_blank">Hexo</a>

	 Theme

	 <a href="https://github.com/Lemonreds/hexo-theme-Nayo" target="_blank">Nayo</a> 

	 </div>	


	
	
</footer> 
    

<!-- Baidu Analytics -->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?636802045446222199ae541e32c8133e"; 
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>




 
  </body>   
  <script src="/js/animation.js"></script>   
</html>